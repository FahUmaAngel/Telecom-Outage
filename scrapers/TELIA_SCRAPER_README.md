# Telia Scraper Documentation

## Overview
The Telia scraper extracts network outage information from Telia's coverage portal.

## Challenge: JavaScript-Rendered Content

### The Problem
Telia's outage information is **not available in static HTML**. The data is loaded dynamically via JavaScript after the page loads.

- **Main Page**: `https://www.telia.se/foretag/support/driftinformation?category=mobila-natet`
- **Actual Data Source** (iframe): `https://coverage.ddc.teliasonera.net/coverageportal_se?appmode=outage`

When you fetch the HTML directly with `requests`, you only get:
- Page structure and layout
- Configuration data
- Localization strings
- **NO actual outage data**

The outage data (incident IDs, affected regions, timestamps) is loaded via JavaScript API calls after the page renders.

## Solutions

### Option 1: Selenium-Based Scraper (Recommended)
**File**: `telia_selenium_scraper.py`

Uses Selenium WebDriver to:
1. Open a real browser (headless Chrome)
2. Load the page and wait for JavaScript to execute
3. Extract incident IDs (e.g., INCSE0425370, INCSE0424577)
4. Extract affected regions (e.g., Stockholms län)
5. Capture detailed outage information

**Pros**:
- Gets actual, real-time outage data
- Handles all JavaScript rendering
- Can interact with the page (click buttons, expand regions)

**Cons**:
- Requires Chrome/ChromeDriver installation
- Slower than simple HTTP requests
- More resource-intensive

**Usage**:
```bash
# Install dependencies
pip install selenium

# Run the scraper
python telia_selenium_scraper.py
```

### Option 2: API Reverse Engineering
**Status**: Partially successful

Attempted to find direct API endpoints:
- `https://coverage.ddc.teliasonera.net/coverageportal_se/Fault/FaultsLastUpdatedInfo` - Returns empty
- `https://coverage.ddc.teliasonera.net/coverageportal_se/ImportantMessages/GetMessages` - Returns empty array
- `https://coverage.ddc.teliasonera.net/coverageportal_se/Fault/AreaTicketList` - Requires session/auth tokens

**Conclusion**: The APIs require session tokens or specific parameters that are generated by the JavaScript application.

### Option 3: Static HTML Parsing
**File**: `telia_scraper_final.py`

**Status**: Not effective for current implementation

This approach can extract:
- Page structure
- Configuration data
- Localization strings

But **cannot** extract:
- Incident IDs
- Outage details
- Affected regions
- Timestamps

## Verified Outages (as of Dec 27, 2025)

Browser investigation confirmed the following active outages:

### Stockholm Region
- **INCSE0425370**: Driftstörning (Service disruption)
  - Start: Sat, Dec 27, 22:44
  - Estimated End: Mon, Dec 29, 14:00

- **INCSE0424577**: Störningar i mobilnätet (Mobile network disruption)
  - Start: Sat, Dec 27, 16:19
  - Estimated End: Mon, Dec 29, 14:00

### Other Affected Regions
- Norrbottens län
- Gävleborgs län
- Jämtlands län
- Dalarnas län
- Västernorrlands län

## Recommended Implementation

For production use, implement the Selenium-based scraper with the following enhancements:

1. **Error Handling**: Add retry logic for network failures
2. **Rate Limiting**: Respect Telia's servers with appropriate delays
3. **Caching**: Cache results to avoid excessive requests
4. **Monitoring**: Log scraping success/failure rates
5. **Fallback**: Have a fallback mechanism if scraping fails

## Integration with Main Project

Update the main scraper runner to use the Selenium-based approach:

```python
from scrapers.telia_selenium_scraper import scrape_with_selenium

# In your main scraper orchestration
telia_data = scrape_with_selenium()
if telia_data['success']:
    # Process and store outages
    for outage in telia_data['outages']:
        # Map to your standard format
        # Save to database
        pass
```

## Alternative: Browser Automation API

If Selenium is too heavy, consider:
- **Playwright**: Modern browser automation (similar to Selenium but faster)
- **Puppeteer**: Node.js-based browser automation
- **Splash**: Lightweight JavaScript rendering service

## Notes

- The scraper must handle JavaScript rendering
- Simple HTTP requests will NOT work for getting outage data
- The iframe URL is the actual data source
- Incident IDs follow the pattern: `INCSE` followed by numbers
- Region names end with "län" (Swedish for county)
